# Feedback Prize - English Language Learning

Code to compete in Kaggle Competition : Feedback Prize - English Language Learning
[link](https://www.kaggle.com/competitions/feedback-prize-english-language-learning)

Model details:

1. Using Roberta embeddings
2. Fine Tuning Roberta for downstreaming task
3. Build NN model using RobertaForSequenceClassification (for regression)
4. Build XGBoost with MultiOuputRegressor on top

Results: 0.44 LB in Kaggle Leader Board
